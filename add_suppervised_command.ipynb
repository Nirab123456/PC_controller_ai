{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PySimpleGUI.PySimpleGUI import Window\n",
    "import sys\n",
    "import os\n",
    "import PySimpleGUI as sg\n",
    "import tkinter as tk\n",
    "from Data_collection_train import TrainingDataFrameApp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Create the tkinter window\n",
    "# window = tk.Tk()\n",
    "# window.geometry(\"400x400\")\n",
    "# window.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# # Create an instance of the TrainingDataFrameApp class\n",
    "# app = TrainingDataFrameApp(window)\n",
    "\n",
    "# # Start the tkinter event loop\n",
    "# window.mainloop()\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, num_columns):\n",
    "        self.df = df\n",
    "        self.num_columns = num_columns\n",
    "\n",
    "    def _custom_logic(self, subset):\n",
    "        cpu_variance = subset['cpu_uses'].var()\n",
    "        memory_variance = subset['memory_uses'].var()\n",
    "        disc_variance = subset['disc_uses'].var()\n",
    "        wifi_variance = subset['Wi_fi_uses'].var()\n",
    "\n",
    "        y_value = 0 \n",
    "        if 1 in subset['Type'].values:\n",
    "            y_value = 0\n",
    "        else:\n",
    "            # hibernate \n",
    "            if cpu_variance > 0.7 and memory_variance > 0.7 and disc_variance > 0.7 and wifi_variance > 0.7:\n",
    "                y_value = .1\n",
    "            # sleep\n",
    "            elif cpu_variance > 0.5 and memory_variance > 0.5 and disc_variance > 0.5 and wifi_variance > 0.5 and \\\n",
    "                    cpu_variance < 0.7 and memory_variance < 0.7 and disc_variance < 0.7 and wifi_variance < 0.7:\n",
    "                y_value = .2\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.3 and memory_variance < 0.3 and disc_variance > 0.5 and wifi_variance < 0.5:\n",
    "                y_value = .3\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.3 and memory_variance < 0.3 and disc_variance < 0.5 and wifi_variance > 0.5:\n",
    "                y_value = .3\n",
    "        return y_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.num_columns\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_columns\n",
    "        end_row = (idx + 1) * self.num_columns\n",
    "        subset = self.df.iloc[start_row:end_row]\n",
    "        y = self._custom_logic(subset)\n",
    "        x = subset.values\n",
    "        x = torch.tensor(x)\n",
    "        x= x.reshape(1,250)\n",
    "\n",
    "        if y is not None:\n",
    "            y = torch.tensor(y)\n",
    "        else:\n",
    "            y = torch.tensor(-1)  # Default value when logic doesn't assign a specific value\n",
    "        return x, y.unsqueeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "layout = [\n",
    "    [sg.Text(\"Enter the name of the file you want to train:\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-FILENAME-', size=(40, 1))],\n",
    "    [sg.Text(\"Enter the number of epochs:\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-NUM_EPOCHS-', size=(40, 1))],\n",
    "    [sg.Button(\"Run\", size=(10, 1), button_color=('white', '#4CAF50'), font=(\"Arial\", 12))],\n",
    "    [sg.Button(\"Exit\", size=(10, 1), button_color=('white', '#D32F2F'), font=(\"Arial\", 12))],\n",
    "    [sg.Output(size=(80, 20), font=(\"Arial\", 12), key='-OUTPUT-')]\n",
    "]\n",
    "\n",
    "# Create the PySimpleGUI window\n",
    "window = sg.Window(\"Program Runner\", layout)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
    "            break\n",
    "        elif event == 'Run':\n",
    "            file_name = values['-FILENAME-']\n",
    "            file_path = file_name + '.csv'\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.astype('float32')\n",
    "            Dataset = CustomDataset(df, 50)\n",
    "            dataloader = DataLoader(Dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(250,50),  # here 5 is the number of dataframe columns or input features\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 1),  \n",
    "                nn.Sigmoid()\n",
    "                \n",
    "            ).to(device)\n",
    "\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            loss_fn = nn.MSELoss()\n",
    "\n",
    "            total_loss = 0\n",
    "            num_batches = len(dataloader)\n",
    "            NUM_EPOCHS = int(values['-NUM_EPOCHS-'])  # Retrieve NUM_EPOCHS from the input field\n",
    "            print_interval = 1\n",
    "            loop_counter = 0\n",
    "            losses = [] \n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                for batch_idx, (x, y) in enumerate(dataloader):\n",
    "                    x = x.to(device)\n",
    "                    y = y.float()\n",
    "                    y = y.to(device)\n",
    "                    model.train()\n",
    "                    # Forward pass\n",
    "                    y_pred = model(x)\n",
    "                    # print(f'shape of x: {x.shape}')\n",
    "                    # print(f'shape of y: {y.shape}')\n",
    "                    # print(f'shape of y_pred: {y_pred.shape}')\n",
    "\n",
    "                    # Compute the loss\n",
    "                    loss = loss_fn(y_pred, y)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Print training progress\n",
    "                    if (batch_idx + 1) % print_interval == 0:\n",
    "                        avg_loss = total_loss / print_interval\n",
    "                        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{num_batches}], Loss: {avg_loss:.4f}')\n",
    "                        total_loss = 0\n",
    "                        losses.append(loss.item())\n",
    "\n",
    "                        # Save the model\n",
    "                        save_path = f'your_model{loop_counter}.pt'\n",
    "                        torch.save(model.state_dict(), save_path)\n",
    "                    \n",
    "                    loop_counter += 1\n",
    "            variance = torch.var(torch.tensor(losses))\n",
    "\n",
    "            std_dev = torch.sqrt(variance)\n",
    "            print(f'Variance: {variance}')\n",
    "            print(f'Standard deviation: {std_dev}')\n",
    "            print(\"Training completed!\")\n",
    "\n",
    "        window['Run'].update(disabled=False)\n",
    "        window.refresh()\n",
    "\n",
    "\n",
    "window.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PySimpleGUI.PySimpleGUI import Window\n",
    "import sys\n",
    "import os\n",
    "import PySimpleGUI as sg\n",
    "import tkinter as tk\n",
    "from Data_collection_train import TrainingDataFrameApp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Create the tkinter window\n",
    "# window = tk.Tk()\n",
    "# window.geometry(\"400x400\")\n",
    "# window.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# # Create an instance of the TrainingDataFrameApp class\n",
    "# app = TrainingDataFrameApp(window)\n",
    "\n",
    "# # Start the tkinter event loop\n",
    "# window.mainloop()\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, num_columns):\n",
    "        self.df = df\n",
    "        self.num_columns = num_columns\n",
    "\n",
    "    def _custom_logic(self, subset):\n",
    "        cpu_variance = subset['cpu_uses'].var()\n",
    "        memory_variance = subset['memory_uses'].var()\n",
    "        disc_variance = subset['disc_uses'].var()\n",
    "        wifi_variance = subset['Wi_fi_uses'].var()\n",
    "\n",
    "        y_value = 0 \n",
    "        if 1 in subset['Type'].values:\n",
    "            y_value = 0\n",
    "        else:\n",
    "            # hibernate \n",
    "            if cpu_variance > 0.7 and memory_variance > 0.7 and disc_variance > 0.7 and wifi_variance > 0.7:\n",
    "                y_value = .1\n",
    "            # sleep\n",
    "            elif cpu_variance > 0.5 and memory_variance > 0.5 and disc_variance > 0.5 and wifi_variance > 0.5 and \\\n",
    "                    cpu_variance < 0.7 and memory_variance < 0.7 and disc_variance < 0.7 and wifi_variance < 0.7:\n",
    "                y_value = .2\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.3 and memory_variance < 0.3 and disc_variance > 0.5 and wifi_variance < 0.5:\n",
    "                y_value = .3\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.3 and memory_variance < 0.3 and disc_variance < 0.5 and wifi_variance > 0.5:\n",
    "                y_value = .3\n",
    "        return y_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.num_columns\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_columns\n",
    "        end_row = (idx + 1) * self.num_columns\n",
    "        subset = self.df.iloc[start_row:end_row]\n",
    "        y = self._custom_logic(subset)\n",
    "        x = subset.values\n",
    "        x = torch.tensor(x)\n",
    "        x= x.reshape(1,250)\n",
    "\n",
    "        if y is not None:\n",
    "            y = torch.tensor(y)\n",
    "        else:\n",
    "            y = torch.tensor(-1)  # Default value when logic doesn't assign a specific value\n",
    "        return x, y.unsqueeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "layout = [\n",
    "    [sg.Text(\"Enter the name of the file you want to train:\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-FILENAME-', size=(40, 1))],\n",
    "    [sg.Text(\"Enter the number of epochs:\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-NUM_EPOCHS-', size=(40, 1))],\n",
    "    [sg.Text(\"Please Enter the Name of your pre trained model if you have one :\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-PRE_TRAINED-', size=(40, 1))],\n",
    "    [sg.Button(\"Run\", size=(10, 1), button_color=('white', '#4CAF50'), font=(\"Arial\", 12))],\n",
    "    [sg.Button(\"Exit\", size=(10, 1), button_color=('white', '#D32F2F'), font=(\"Arial\", 12))],\n",
    "    [sg.Output(size=(80, 20), font=(\"Arial\", 12), key='-OUTPUT-')]\n",
    "]\n",
    "\n",
    "# Create the PySimpleGUI window\n",
    "window = sg.Window(\"Program Runner\", layout)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
    "            break\n",
    "        elif event == 'Run':\n",
    "            file_name = values['-FILENAME-']\n",
    "            file_path = file_name + '.csv'\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.astype('float32')\n",
    "            Dataset = CustomDataset(df, 50)\n",
    "            dataloader = DataLoader(Dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(250,50),  # here 5 is the number of dataframe columns or input features\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 1),  \n",
    "                nn.Sigmoid()\n",
    "                \n",
    "            ).to(device)\n",
    "            model_state_name = values['-PRE_TRAINED-']\n",
    "            model_state_name = model_state_name + '.pt'\n",
    "\n",
    "            if model_state_name != '':\n",
    "                model.load_state_dict(torch.load(model_state_name))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            loss_fn = nn.MSELoss()\n",
    "\n",
    "            total_loss = 0\n",
    "            num_batches = len(dataloader)\n",
    "            NUM_EPOCHS = int(values['-NUM_EPOCHS-'])  # Retrieve NUM_EPOCHS from the input field\n",
    "            print_interval = 1\n",
    "            loop_counter = 0\n",
    "            losses = [] \n",
    "            writer = SummaryWriter()\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                for batch_idx, (x, y) in enumerate(dataloader):\n",
    "                    x = x.to(device)\n",
    "                    y = y.float()\n",
    "                    y = y.to(device)\n",
    "                    model.train()\n",
    "                    # Forward pass\n",
    "                    y_pred = model(x)\n",
    "\n",
    "                    # Compute the loss\n",
    "                    loss = loss_fn(y_pred, y)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Print training progress\n",
    "                    if (batch_idx + 1) % print_interval == 0:\n",
    "                        avg_loss = total_loss / print_interval\n",
    "                        total_loss = 0\n",
    "                        variance = torch.var(torch.tensor(losses))\n",
    "                        std_dev = torch.sqrt(variance)\n",
    "                        losses.append(loss.item())\n",
    "                        writer.add_scalar('Loss', avg_loss, epoch * num_batches + batch_idx)\n",
    "                        writer.add_scalar('Variance', variance, epoch * num_batches + batch_idx)\n",
    "                        # Save the model\n",
    "                        save_path = f'your_model{loop_counter}.pt'\n",
    "                        torch.save(model.state_dict(), save_path)\n",
    "                    \n",
    "                    loop_counter += 1\n",
    "            writer.close()\n",
    "            print(\"Thank you for your patience Training has been compleated !\")\n",
    "        window['Run'].update(disabled=False)\n",
    "        window.refresh()\n",
    "\n",
    "\n",
    "window.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_uses</th>\n",
       "      <th>memory_uses</th>\n",
       "      <th>Wi_fi_uses</th>\n",
       "      <th>disc_uses</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.053162e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.226657e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.865272e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.971305e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.732949e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.023988e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004543</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.045526e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.288622e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.878903e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.802318e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467638e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.972842e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.610980e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.826015e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.220318</td>\n",
       "      <td>1.871330e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cpu_uses   memory_uses  Wi_fi_uses  disc_uses  Type\n",
       "0   0.000000  0.000000e+00         0.0        0.0   0.0\n",
       "1   0.000000  1.053162e-02         0.0        0.0   0.0\n",
       "2   0.000000  1.226657e-01         0.0        0.0   0.0\n",
       "3   0.000000  0.000000e+00         0.0        0.0   1.0\n",
       "4   0.000000  1.865272e-01         0.0        0.0   0.0\n",
       "5   0.000000  2.971305e-03         0.0        0.0   0.0\n",
       "6   0.000000  9.732949e-02         0.0        0.0   0.0\n",
       "7   0.000000  9.023988e-05         0.0        0.0   0.0\n",
       "8   0.004543  9.999999e-01         0.0        0.0   0.0\n",
       "9   0.000000  1.045526e-03         0.0        0.0   0.0\n",
       "10  0.000000  2.288622e-02         0.0        0.0   0.0\n",
       "11  0.000000  4.878903e-04         0.0        0.0   0.0\n",
       "12  0.000000  1.802318e-02         0.0        0.0   0.0\n",
       "13  0.000000  1.467638e-04         0.0        0.0   0.0\n",
       "14  0.000000  7.972842e-04         0.0        0.0   0.0\n",
       "15  1.000000  6.610980e-07         0.0        0.0   0.0\n",
       "16  0.000000  4.826015e-03         0.0        0.0   0.0\n",
       "17  0.220318  1.871330e-01         0.0        0.0   0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('12.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.2714e-04],\n",
      "         [6.1944e-05],\n",
      "         [2.1338e-04],\n",
      "         [7.0907e-05],\n",
      "         [1.7519e-04]],\n",
      "\n",
      "        [[7.0177e-05],\n",
      "         [7.2420e-05],\n",
      "         [7.8432e-05],\n",
      "         [7.2725e-05],\n",
      "         [8.4925e-05]],\n",
      "\n",
      "        [[7.1332e-05],\n",
      "         [7.2189e-05],\n",
      "         [6.4459e-05],\n",
      "         [1.4727e-04],\n",
      "         [1.4595e-04]],\n",
      "\n",
      "        [[8.0511e-05],\n",
      "         [6.8218e-05],\n",
      "         [7.1563e-05],\n",
      "         [7.2725e-05],\n",
      "         [1.7509e-04]],\n",
      "\n",
      "        [[1.4545e-04],\n",
      "         [3.1680e-05],\n",
      "         [7.2189e-05],\n",
      "         [7.8436e-05],\n",
      "         [6.1926e-05]],\n",
      "\n",
      "        [[7.2420e-05],\n",
      "         [1.4171e-04],\n",
      "         [7.0143e-05],\n",
      "         [1.6354e-04],\n",
      "         [7.0907e-05]],\n",
      "\n",
      "        [[1.2714e-04],\n",
      "         [8.4925e-05],\n",
      "         [7.0125e-05],\n",
      "         [7.1842e-05],\n",
      "         [6.8203e-05]],\n",
      "\n",
      "        [[6.1851e-05],\n",
      "         [1.7536e-04],\n",
      "         [7.8425e-05],\n",
      "         [1.4636e-04],\n",
      "         [7.2420e-05]],\n",
      "\n",
      "        [[6.1926e-05],\n",
      "         [7.2189e-05],\n",
      "         [6.2052e-05],\n",
      "         [6.8963e-05],\n",
      "         [2.4652e-04]],\n",
      "\n",
      "        [[7.0028e-05],\n",
      "         [7.0177e-05],\n",
      "         [7.0907e-05],\n",
      "         [6.8203e-05],\n",
      "         [1.2714e-04]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.float() \n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        print(y_pred)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = CustomDataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                nn.Linear(5, 30),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(30, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Tanh()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\rl_computer_controll\\task_controller\\add_suppervised_command.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#Y101sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\rl_computer_controll\\task_controller\\add_suppervised_command.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mfloat()  \u001b[39m# Convert y to torch.float\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32md:\\rl_computer_controll\\task_controller\\add_suppervised_command.ipynb Cell 12\u001b[0m in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_custom_logic(subset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m x \u001b[39m=\u001b[39m subset\u001b[39m.\u001b[39mvalues\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/rl_computer_controll/task_controller/add_suppervised_command.ipynb#X65sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(x), torch\u001b[39m.\u001b[39;49mtensor(y)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for x, y in dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.float()  # Convert y to torch.float\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_uses</th>\n",
       "      <th>memory_uses</th>\n",
       "      <th>Wi_fi_uses</th>\n",
       "      <th>disc_uses</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.176540e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.979335e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.353317e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.089447e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.464073e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.878832e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.407529e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.718939e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.066849e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.554609e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.433418e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.504638e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.572928e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.503427e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.328572e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.077191e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.086325e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.584181e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003649</td>\n",
       "      <td>7.464073e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.554609e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.407594e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.178817e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.878832e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.981755</td>\n",
       "      <td>6.504638e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.009706e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001759</td>\n",
       "      <td>9.964163e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.353317e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.718939e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008307e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.471109e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.330524e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.491504e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.095855e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.407627e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.997003</td>\n",
       "      <td>6.504638e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.878832e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.178817e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.554609e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.486950e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.460360e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.005864</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.004047e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.464073e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.353317e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.330199e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.090729e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.718939e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000729e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cpu_uses   memory_uses  Wi_fi_uses  disc_uses  Type\n",
       "0   0.000000  0.000000e+00         0.0        0.0   1.0\n",
       "1   0.000000  3.176540e-03         0.0        0.0   0.0\n",
       "2   0.000000  9.979335e-01         0.0        0.0   1.0\n",
       "3   0.000000  5.353317e-04         0.0        0.0   0.0\n",
       "4   0.000000  6.089447e-02         0.0        0.0   0.0\n",
       "5   0.000000  7.464073e-04         0.0        0.0   0.0\n",
       "6   0.000000  8.878832e-05         0.0        0.0   0.0\n",
       "7   0.000000  2.407529e-02         0.0        0.0   0.0\n",
       "8   0.000000  0.000000e+00         0.0        0.0   0.0\n",
       "9   0.000000  2.718939e-02         0.0        0.0   0.0\n",
       "10  0.000000  2.066849e-02         0.0        0.0   0.0\n",
       "11  0.000000  1.554609e-04         0.0        0.0   0.0\n",
       "12  0.000000  9.433418e-02         0.0        0.0   0.0\n",
       "13  1.000000  6.504638e-07         0.0        0.0   0.0\n",
       "14  0.000000  7.572928e-02         0.0        0.0   0.0\n",
       "15  0.000000  2.503427e-01         0.0        0.0   0.0\n",
       "17  0.000000  1.328572e-03         0.0        0.0   0.0\n",
       "18  0.000000  2.077191e-02         0.0        0.0   0.0\n",
       "20  0.000000  0.000000e+00         0.0        0.0   0.0\n",
       "21  0.000000  6.086325e-02         0.0        0.0   0.0\n",
       "22  0.000000  7.584181e-02         0.0        0.0   0.0\n",
       "23  0.003649  7.464073e-04         0.0        0.0   0.0\n",
       "24  0.000000  1.554609e-04         0.0        0.0   0.0\n",
       "25  0.000000  2.407594e-02         0.0        0.0   0.0\n",
       "26  0.000000  3.178817e-03         0.0        0.0   0.0\n",
       "27  0.000000  8.878832e-05         0.0        0.0   0.0\n",
       "28  0.981755  6.504638e-07         0.0        0.0   0.0\n",
       "29  0.000000  2.009706e-02         0.0        0.0   0.0\n",
       "30  0.001759  9.964163e-01         0.0        0.0   1.0\n",
       "31  0.000000  5.353317e-04         0.0        0.0   0.0\n",
       "32  0.000000  0.000000e+00         0.0        0.0   1.0\n",
       "33  0.000000  2.718939e-02         0.0        0.0   0.0\n",
       "34  0.000000  2.008307e-02         0.0        0.0   0.0\n",
       "35  0.000000  2.471109e-01         0.0        0.0   0.0\n",
       "36  0.000000  1.330524e-03         0.0        0.0   0.0\n",
       "37  0.000000  9.491504e-02         0.0        0.0   0.0\n",
       "38  0.000000  6.095855e-02         0.0        0.0   0.0\n",
       "39  0.000000  2.407627e-02         0.0        0.0   0.0\n",
       "40  0.997003  6.504638e-07         0.0        0.0   0.0\n",
       "41  0.000000  8.878832e-05         0.0        0.0   0.0\n",
       "42  0.000000  3.178817e-03         0.0        0.0   0.0\n",
       "43  0.000000  1.554609e-04         0.0        0.0   0.0\n",
       "44  0.000000  9.486950e-02         0.0        0.0   0.0\n",
       "45  0.000000  2.460360e-01         0.0        0.0   0.0\n",
       "46  0.005864  1.000000e+00         0.0        0.0   1.0\n",
       "47  0.000000  2.004047e-02         0.0        0.0   0.0\n",
       "48  0.000000  7.464073e-04         0.0        0.0   0.0\n",
       "49  0.000000  5.353317e-04         0.0        0.0   0.0\n",
       "50  0.000000  1.330199e-03         0.0        0.0   0.0\n",
       "51  0.000000  0.000000e+00         0.0        0.0   1.0\n",
       "52  0.000000  8.090729e-02         0.0        0.0   0.0\n",
       "53  0.000000  0.000000e+00         0.0        0.0   0.0\n",
       "54  0.000000  2.718939e-02         0.0        0.0   0.0\n",
       "55  0.000000  2.000729e-02         0.0        0.0   0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0470],\n",
       "        [-0.0080],\n",
       "        [ 0.0585],\n",
       "        [-0.0079],\n",
       "        [-0.0081]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, num_columns):\n",
    "        self.df = df\n",
    "        self.num_columns = num_columns\n",
    "\n",
    "    def _custom_logic(self, subset):\n",
    "\n",
    "        target_value = subset.sum().values.sum()\n",
    "        return target_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.num_columns + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_columns\n",
    "        end_row = (idx + 1) * self.num_columns\n",
    "        subset = self.df.iloc[start_row:end_row]\n",
    "        y = self._custom_logic(subset)\n",
    "        x = subset.values\n",
    "        return torch.tensor(x), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS=10\n",
    "NUM_COLS=5\n",
    "\n",
    "# Select the desired subset of data chronologically\n",
    "selected_data = df.iloc[:NUM_ROWS, :NUM_COLS]\n",
    "# Convert the selected data to a NumPy array\n",
    "data_array = selected_data.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
