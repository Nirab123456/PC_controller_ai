{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from action import Process_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_t = Process_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_off = pr_t.turn_off_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PySimpleGUI.PySimpleGUI import Window\n",
    "import sys\n",
    "import os\n",
    "import PySimpleGUI as sg\n",
    "import tkinter as tk\n",
    "from Data_collection_train import TrainingDataFrameApp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "sg.theme(\"DarkAmber\")   \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    window = sg.Window(\"Training DataFrame App\")  # Set the window title here\n",
    "    app = TrainingDataFrameApp(window)\n",
    "\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WINDOW_CLOSED:\n",
    "            break\n",
    "        elif event == 'Continue':\n",
    "            app.collect_data()\n",
    "        elif event == 'Save':\n",
    "            app.save_data()\n",
    "\n",
    "    window.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, num_columns):\n",
    "        self.df = df\n",
    "        self.num_columns = num_columns\n",
    "\n",
    "    def _custom_logic(self, subset):\n",
    "        cpu_variance = subset['cpu_uses'].var()\n",
    "        memory_variance = subset['memory_uses'].var()\n",
    "        disc_variance = subset['disc_uses'].var()\n",
    "        wifi_variance = subset['Wi_fi_uses'].var()\n",
    "        cpu_mean = subset['cpu_uses'].mean()\n",
    "        memory_mean = subset['memory_uses'].mean()\n",
    "        disc_mean = subset['disc_uses'].mean()\n",
    "        wifi_mean = subset['Wi_fi_uses'].mean()\n",
    "\n",
    "        y_value = 0 \n",
    "        if 1 in subset['Type'].values:\n",
    "            y_value = 0\n",
    "        else:\n",
    "            # hibernate \n",
    "            if cpu_variance > 0.5 and memory_variance > 0.5 and disc_variance > 0.5 and wifi_variance > 0.5  and \\\n",
    "                    cpu_mean > 0.5 and memory_mean > 0.5 and disc_mean > 0.5 and wifi_mean > 0.5:\n",
    "                y_value = .1\n",
    "            # sleep\n",
    "            elif cpu_variance > 0.3 and memory_variance > 0.3 and disc_variance > 0.3 and wifi_variance > 0.3 and \\\n",
    "                    cpu_variance < 0.3 and memory_variance < 0.5 and disc_variance < 0.5 and wifi_variance < 0.5 and \\\n",
    "                        cpu_mean > 0.3 and memory_mean > 0.3 and disc_mean > 0.3 and wifi_mean > 0.3:\n",
    "                y_value = .2\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.1 and memory_variance < 0.1 and disc_variance < 0.1 and wifi_variance < 0.01 and \\\n",
    "                    cpu_mean < 0.1 and memory_mean < 0.1 and disc_mean < 0.1 and wifi_mean < 0.1:\n",
    "                y_value = .3\n",
    "        return y_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.num_columns\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_columns\n",
    "        end_row = (idx + 1) * self.num_columns\n",
    "        subset = self.df.iloc[start_row:end_row]\n",
    "        y = self._custom_logic(subset)\n",
    "        x = subset.values\n",
    "        x = torch.tensor(x)\n",
    "        x= x.reshape(1,250)\n",
    "\n",
    "        if y is not None:\n",
    "            y = torch.tensor(y)\n",
    "        else:\n",
    "            y = torch.tensor(-1)  # Default value when logic doesn't assign a specific value\n",
    "        return x, y.unsqueeze(-1)\n",
    "\n",
    "\n",
    "user_id = sys.argv[1]\n",
    "model_name = sys.argv[2]\n",
    "\n",
    "\n",
    "layout = [\n",
    "    [sg.Text(\"Enter the name of the file you want to train((.csv)extensin not needed):\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-FILENAME-', size=(40, 1))],\n",
    "    [sg.Text(\"Enter the number of epochs:\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-NUM_EPOCHS-', size=(40, 1))],\n",
    "    [sg.Button(\"Run\", size=(10, 1), button_color=('white', '#4CAF50'), font=(\"Arial\", 12))],\n",
    "    [sg.Button(\"Exit\", size=(10, 1), button_color=('white', '#D32F2F'), font=(\"Arial\", 12))],\n",
    "    [sg.Output(size=(80, 20), font=(\"Arial\", 12), key='-OUTPUT-')]\n",
    "]\n",
    "\n",
    "# Create the PySimpleGUI window\n",
    "window = sg.Window(\"Program Runner\", layout)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
    "            break\n",
    "        elif event == 'Run':\n",
    "            file_name = values['-FILENAME-']\n",
    "            file_path = file_name + '.csv'\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.astype('float32')\n",
    "            dataset = CustomDataset(df, 50)\n",
    "            dataloader = DataLoader(dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(250,50),  # here 5 is the number of dataframe columns or input features\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 1),  \n",
    "                nn.Sigmoid()\n",
    "                \n",
    "            ).to(device)\n",
    "            user_id = sys.argv[1]# Retrieve the user id from the input field from subprocess\n",
    "            model_name = sys.argv[2]# Retrieve the model name from the input field from subprocess\n",
    "            model_state_name = model_name#.pt was add in Ui_main_frame.py\n",
    "            if os.path.isfile(model_state_name):\n",
    "                model.load_state_dict(torch.load(model_state_name))\n",
    "            else:\n",
    "                model= model.to(device)\n",
    "                \n",
    "\n",
    "\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            loss_fn = nn.MSELoss()\n",
    "\n",
    "            total_loss = 0\n",
    "            num_batches = len(dataloader)\n",
    "            NUM_EPOCHS = int(values['-NUM_EPOCHS-'])  # Retrieve NUM_EPOCHS from the input field\n",
    "            print_interval = 1\n",
    "            loop_counter = 0\n",
    "            losses = [] \n",
    "            writer = SummaryWriter()\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                for batch_idx, (x, y) in enumerate(dataloader):\n",
    "                    x = x.to(device)\n",
    "                    y = y.float()\n",
    "                    y = y.to(device)\n",
    "                    model.train()\n",
    "                    # Forward pass\n",
    "                    y_pred = model(x)\n",
    "\n",
    "                    # Compute the loss\n",
    "                    loss = loss_fn(y_pred, y)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Print training progress\n",
    "                    if (batch_idx + 1) % print_interval == 0:\n",
    "                        avg_loss = total_loss / print_interval\n",
    "                        total_loss = 0\n",
    "                        variance = torch.var(torch.tensor(losses))\n",
    "                        std_dev = torch.sqrt(variance)\n",
    "                        losses.append(loss.item())\n",
    "                        writer.add_scalar('Loss', avg_loss, epoch * num_batches + batch_idx)\n",
    "                        writer.add_scalar('Variance', variance, epoch * num_batches + batch_idx)\n",
    "                        # Save the model\n",
    "                        save_path = model_name #.pt has been added in Ui_main_frame.py\n",
    "                        torch.save(model.state_dict(), save_path)\n",
    "                    \n",
    "                    loop_counter += 1\n",
    "            writer.close()\n",
    "            print(\"Thank you for your patience Training has been compleated !\")\n",
    "        window['Run'].update(disabled=False)\n",
    "        window.refresh()\n",
    "\n",
    "\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PySimpleGUI.PySimpleGUI import Window\n",
    "import sys\n",
    "import os\n",
    "import PySimpleGUI as sg\n",
    "import tkinter as tk\n",
    "from Data_collection_train import TrainingDataFrameApp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "sg.theme(\"DarkAmber\")   \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    window = sg.Window(\"Training DataFrame App\")  # Set the window title here\n",
    "    app = TrainingDataFrameApp(window)\n",
    "\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WINDOW_CLOSED:\n",
    "            break\n",
    "        elif event == 'Continue':\n",
    "            app.collect_data()\n",
    "        elif event == 'Save':\n",
    "            app.save_data()\n",
    "\n",
    "    window.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, num_columns):\n",
    "        self.df = df\n",
    "        self.num_columns = num_columns\n",
    "\n",
    "    def _custom_logic(self, subset):\n",
    "        cpu_variance = subset['cpu_uses'].var()\n",
    "        memory_variance = subset['memory_uses'].var()\n",
    "        disc_variance = subset['disc_uses'].var()\n",
    "        wifi_variance = subset['Wi_fi_uses'].var()\n",
    "\n",
    "        y_value = 0 \n",
    "        if 1 in subset['Type'].values:\n",
    "            y_value = 0\n",
    "        else:\n",
    "            # hibernate \n",
    "            if cpu_variance > 0.7 and memory_variance > 0.7 and disc_variance > 0.7 and wifi_variance > 0.7:\n",
    "                y_value = .1\n",
    "            # sleep\n",
    "            elif cpu_variance > 0.5 and memory_variance > 0.5 and disc_variance > 0.5 and wifi_variance > 0.5 and \\\n",
    "                    cpu_variance < 0.7 and memory_variance < 0.7 and disc_variance < 0.7 and wifi_variance < 0.7:\n",
    "                y_value = .2\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.3 and memory_variance < 0.3 and disc_variance > 0.5 and wifi_variance < 0.5:\n",
    "                y_value = .3\n",
    "            # shutoff display\n",
    "            elif cpu_variance < 0.3 and memory_variance < 0.3 and disc_variance < 0.5 and wifi_variance > 0.5:\n",
    "                y_value = .3\n",
    "        return y_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.num_columns\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_columns\n",
    "        end_row = (idx + 1) * self.num_columns\n",
    "        subset = self.df.iloc[start_row:end_row]\n",
    "        y = self._custom_logic(subset)\n",
    "        x = subset.values\n",
    "        x = torch.tensor(x)\n",
    "        x= x.reshape(1,250)\n",
    "\n",
    "        if y is not None:\n",
    "            y = torch.tensor(y)\n",
    "        else:\n",
    "            y = torch.tensor(-1)  # Default value when logic doesn't assign a specific value\n",
    "        return x, y.unsqueeze(-1)\n",
    "\n",
    "\n",
    "user_id = sys.argv[1]\n",
    "model_name = sys.argv[2]\n",
    "\n",
    "\n",
    "layout = [\n",
    "    [sg.Text(\"Enter the name of the file you want to train((.csv)extensin not needed):\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-FILENAME-', size=(40, 1))],\n",
    "    [sg.Text(\"Enter the number of epochs:\", font=(\"Arial\", 12))],\n",
    "    [sg.Input(key='-NUM_EPOCHS-', size=(40, 1))],\n",
    "    [sg.Button(\"Run\", size=(10, 1), button_color=('white', '#4CAF50'), font=(\"Arial\", 12))],\n",
    "    [sg.Button(\"Exit\", size=(10, 1), button_color=('white', '#D32F2F'), font=(\"Arial\", 12))],\n",
    "    [sg.Output(size=(80, 20), font=(\"Arial\", 12), key='-OUTPUT-')]\n",
    "]\n",
    "\n",
    "# Create the PySimpleGUI window\n",
    "window = sg.Window(\"Program Runner\", layout)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
    "            break\n",
    "        elif event == 'Run':\n",
    "            file_name = values['-FILENAME-']\n",
    "            file_path = file_name + '.csv'\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.astype('float32')\n",
    "            dataset = CustomDataset(df, 50)\n",
    "            dataloader = DataLoader(dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "            model = nn.Sequential(\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(250,50),  # here 5 is the number of dataframe columns or input features\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 1),  \n",
    "                nn.Sigmoid()\n",
    "                \n",
    "            ).to(device)\n",
    "            user_id = sys.argv[1]# Retrieve the user id from the input field from subprocess\n",
    "            model_name = sys.argv[2]# Retrieve the model name from the input field from subprocess\n",
    "            model_state_name = model_name#.pt was add in Ui_main_frame.py\n",
    "            if os.path.isfile(model_state_name):\n",
    "                model.load_state_dict(torch.load(model_state_name))\n",
    "            else:\n",
    "                model= model.to(device)\n",
    "                \n",
    "\n",
    "\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            loss_fn = nn.MSELoss()\n",
    "\n",
    "            total_loss = 0\n",
    "            num_batches = len(dataloader)\n",
    "            NUM_EPOCHS = int(values['-NUM_EPOCHS-'])  # Retrieve NUM_EPOCHS from the input field\n",
    "            print_interval = 1\n",
    "            loop_counter = 0\n",
    "            losses = [] \n",
    "            writer = SummaryWriter()\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                for batch_idx, (x, y) in enumerate(dataloader):\n",
    "                    x = x.to(device)\n",
    "                    y = y.float()\n",
    "                    y = y.to(device)\n",
    "                    model.train()\n",
    "                    # Forward pass\n",
    "                    y_pred = model(x)\n",
    "\n",
    "                    # Compute the loss\n",
    "                    loss = loss_fn(y_pred, y)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Print training progress\n",
    "                    if (batch_idx + 1) % print_interval == 0:\n",
    "                        avg_loss = total_loss / print_interval\n",
    "                        total_loss = 0\n",
    "                        variance = torch.var(torch.tensor(losses))\n",
    "                        std_dev = torch.sqrt(variance)\n",
    "                        losses.append(loss.item())\n",
    "                        writer.add_scalar('Loss', avg_loss, epoch * num_batches + batch_idx)\n",
    "                        writer.add_scalar('Variance', variance, epoch * num_batches + batch_idx)\n",
    "                        # Save the model\n",
    "                        save_path = model_name #.pt has been added in Ui_main_frame.py\n",
    "                        torch.save(model.state_dict(), save_path)\n",
    "                    \n",
    "                    loop_counter += 1\n",
    "            writer.close()\n",
    "            print(\"Thank you for your patience Training has been compleated !\")\n",
    "        window['Run'].update(disabled=False)\n",
    "        window.refresh()\n",
    "\n",
    "\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
